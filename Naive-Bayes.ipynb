{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: fcrary@ucsu.Colorado.EDU (Frank Crary)\n",
      "Subject: Re: Riddle me this...\n",
      "Nntp-Posting-Host: ucsu.colorado.edu\n",
      "Organization: University of Colorado, Boulder\n",
      "Distribution: usa\n",
      "Lines: 16\n",
      "\n",
      "In article <1r1lp1INN752@mojo.eng.umd.edu> chuck@eng.umd.edu (Chuck Harris - WA3UQV) writes:\n",
      ">>If so, why was CS often employed against tunnels in Vietnam?\n",
      "\n",
      ">CS \"tear-gas\" was used in Vietnam because it makes you wretch so hard that\n",
      ">your stomach comes out thru your throat.  Well, not quite that bad, but\n",
      ">you can't really do much to defend yourself while you are blowing cookies.\n",
      "\n",
      "I think the is BZ gas, not CS or CN. BZ gas exposure results in projectile\n",
      "vomiting, loss of essentially all muscle control, inability to concentrate\n",
      "or think rationally and fatal reactions in a significant fraction of\n",
      "the population. For that reason its use is limited to military\n",
      "applications.\n",
      "\n",
      "                                                          Frank Crary\n",
      "                                                          CU Boulder\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'talk.politics.guns',\n",
    "              'sci.space']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "print(train.data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1 ... 1 2 2]\n",
      " probabilities are [0.2964793082149475, 0.3662754786905497, 0.3372452130945028],\n",
      " in total their sum is 1.0\n"
     ]
    }
   ],
   "source": [
    "y_train = train.target\n",
    "print(y_train)\n",
    "\n",
    "def prob_of_class(target_list, num_of_classes):\n",
    "    total = len(target_list)\n",
    "    probabilities = [0 for _ in range(num_of_classes)]\n",
    "\n",
    "    for y in target_list:\n",
    "        probabilities[y] += 1\n",
    "    probabilities = [prob/total for prob in probabilities]\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "prob_class = prob_of_class(y_train, len(train.target_names))\n",
    "print(f' probabilities are {prob_class},\\n in total their sum is {sum(prob_class)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aario', 'aaron', ..., 'zoology', 'zv', 'Ã¿'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", min_df=5,token_pattern=\"[^\\W\\d_]+\", binary=True)\n",
    "D = vectorizer.fit_transform(train.data)\n",
    "D_test = vectorizer.transform(test.data)\n",
    "\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.606241954135954, -4.946906632387673, -2.7203111961144097]\n"
     ]
    }
   ],
   "source": [
    "naive_index = np.where(vectorizer.get_feature_names_out() == 'naive')[0][0]\n",
    "alpha = 10 ** -5\n",
    "\n",
    "def log_prob_laplace(word_matrix, alpha, num_of_classes, target_list, key_word_index):\n",
    "    total_key_words = [0 for _ in range(num_of_classes)]\n",
    "    total_words_classes = [0 for _ in range(num_of_classes)]\n",
    "    total_words_document = word_matrix.sum(axis=1).getA().flatten()\n",
    "\n",
    "    for i, y in enumerate(target_list):\n",
    "        total_key_words[y] += word_matrix[i, key_word_index]\n",
    "        total_words_classes[y] += total_words_document[i]\n",
    "    \n",
    "    probabilities = [0 for _ in range(num_of_classes)]\n",
    "    for y in range(num_of_classes):\n",
    "        probabilities[y] = np.log((total_key_words[y] + alpha) / (total_words_document[y] + alpha * sum(total_words_document)))\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "print(log_prob_laplace(D, alpha, 3, y_train, naive_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-233.30338553250704, -286.51384204724354, -48.534473290952164]\n"
     ]
    }
   ],
   "source": [
    "num_documents = len(y_train)\n",
    "num_words = len(vectorizer.get_feature_names_out())\n",
    "\n",
    "# words_class_log_prob = [log_prob_laplace(D, alpha, 3, y_train, word_index) for word_index in range(num_words)]\n",
    "# print(words_class_log_prob)\n",
    "# print(words_class_log_prob[naive_index])\n",
    "\n",
    "words_first_doc = []\n",
    "for i in range(num_words):\n",
    "    if D[0, i] == 1:\n",
    "        words_first_doc.append(i)\n",
    "\n",
    "words_first_doc_prob = [log_prob_laplace(D, alpha, 3, y_train, word_index) for word_index in words_first_doc]\n",
    "probabilities_first_doc = [np.log(prob_y) for prob_y in prob_class]\n",
    "for word_prob in words_first_doc_prob:\n",
    "    for y in range(len(probabilities_first_doc)):\n",
    "        probabilities_first_doc[y] += word_prob[y]\n",
    "    \n",
    "print(probabilities_first_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
